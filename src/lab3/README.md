# Распределенные системы: Лабораторные работы с MPJ

## Содержание
1. [Задание 3.1: Программа с пробниками](#задание-31-программа-с-пробниками)
2. [Задание 3: Задача фильтрации](#задание-3-задача-фильтрации)
3. [Теоретическая справка](#теоретическая-справка)
4. [Описание реализации](#описание-реализации)

## Задание 3.1: Программа с пробниками

### Описание
Требуется дополнить и выполнить программу с использованием пробников (Probe) в MPI.

### Реализация
В этом задании мы модифицировали исходный код, добавив использование `Probe` для определения размера входящих сообщений перед их приемом. Вот ключевой фрагмент кода:

```java
Status st = MPI.COMM_WORLD.Probe(MPI.ANY_SOURCE, TAG);
int count = st.Get_count(MPI.INT);
int[] back_buf = new int[count];
MPI.COMM_WORLD.Recv(back_buf, 0, count, MPI.INT, st.source, TAG);
```

## Задание 3: Задача фильтрации

### Описание
Реализовать задачу фильтрации с использованием неблокирующих обменов, Waitall() и пробников. Программа должна поддерживать переменное количество процессов.

### Реализация
Мы создали программу, которая динамически распределяет процессы на три уровня:
1. Процессы первого уровня отправляют данные.
2. Процессы второго уровня получают, сортируют и отправляют данные.
3. Финальный процесс собирает все данные и выполняет окончательную сортировку.

## Теоретическая справка

### Probe в MPI
`Probe` - метод в MPI, который позволяет проверить наличие входящего сообщения без его фактического получения.

Параметры `Probe`:
- `source`: ранг отправителя или `MPI.ANY_SOURCE`
- `tag`: тег сообщения или `MPI.ANY_TAG`

Возвращает объект `Status`, содержащий информацию о сообщении.

### Неблокирующие обмены
Неблокирующие операции (Isend, Irecv) позволяют инициировать передачу данных и продолжить выполнение программы, не дожидаясь завершения операции.

## Сравнение с блокирующими операциями

1. Гибкость: Неблокирующие операции позволяют более гибко управлять потоком выполнения программы.
2. Производительность: В сценариях с интенсивным обменом данными неблокирующие операции могут обеспечить лучшую производительность за счет перекрытия коммуникаций и вычислений.
3. Сложность: Неблокирующие операции требуют более тщательного управления и могут усложнить код.

### Waitall
`Waitall` используется для ожидания завершения группы неблокирующих операций.

## Описание реализации

### Структура программы
Программа разделена на три основных компонента:

1. **Процессы первого уровня**
    - Отправляют данные процессам второго уровня.
    - Используют `Isend` для неблокирующей отправки.

   ```java
   Request request = MPI.COMM_WORLD.Isend(dataToSend, 0, dataToSend.length, MPI.INT, receiver, 0);
   request.Wait();
   ```

2. **Процессы второго уровня**
    - Получают данные от процессов первого уровня.
    - Сортируют полученные данные.
    - Отправляют отсортированные данные финальному процессу.

   ```java
   Status status = MPI.COMM_WORLD.Probe(MPI.ANY_SOURCE, MPI.ANY_TAG);
   int count = status.Get_count(MPI.INT);
   receivedData[i] = new int[count];
   requests[i] = MPI.COMM_WORLD.Irecv(receivedData[i], 0, count, MPI.INT, status.source, status.tag);
   ```

3. **Финальный процесс**
    - Собирает отсортированные данные от процессов второго уровня.
    - Выполняет окончательную сортировку.

   ```java
   Status status = MPI.COMM_WORLD.Probe(MPI.ANY_SOURCE, MPI.ANY_TAG);
   int count = status.Get_count(MPI.INT);
   sortedDataFromReceivers[i] = new int[count];
   requests[i] = MPI.COMM_WORLD.Irecv(sortedDataFromReceivers[i], 0, count, MPI.INT, status.source, status.tag);
   ```

### Динамическое распределение процессов
Реализован класс `ProcessConfig`, который вычисляет оптимальное распределение процессов на основе их общего количества:

```java
this.numSecondLevel = Math.max(2, (int) Math.sqrt(totalProcesses - 1));
this.numFirstLevel = totalProcesses - this.numSecondLevel - 1;
```

### Использование неблокирующих операций
Программа использует `Isend` и `Irecv` для неблокирующей передачи данных, что позволяет эффективно использовать вычислительные ресурсы.

### Обработка ошибок и вывод информации
Реализована обработка исключений и информативный вывод о ходе выполнения программы, что облегчает отладку и понимание процесса работы.

## Как запустить программу

1. Скомпилируйте программу:
   ```
   javac -cp .:$MPJ_HOME/lib/mpj.jar Main.java
   ```

2. Запустите программу на нескольких процессорах (например, на 9):
   ```
   mpjrun.sh -np 9 Main
   ```

## Заключение

В данной лабораторной работе была реализована задача фильтрации с использованием MPJ Express. Программа демонстрирует эффективное использование неблокирующих обменов, пробников и динамического распределения процессов. Эта реализация обеспечивает гибкость и масштабируемость, позволяя работать с различным количеством процессов и эффективно обрабатывать данные в распределенной среде.